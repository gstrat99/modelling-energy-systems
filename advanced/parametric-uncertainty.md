# Parametric uncertainty

(content:uncert:introduction)=
## Introduction
There is much uncertainty surrounding future developments in technology, economics, and policy. For example, think of the uncertainty involved in forecasting natural gas prices and the impact a global pandemic or regional war can have on prices. It is important to account for uncertainty in modelling in order to make predictions of the future. This document gives a brief overview of uncertainty in energy system optimisation models, including different classifications of uncertainty and examples. Then, we discuss how to characterise, or quantify uncertainty. Next we describe sensitivity analysis and robustness analysis of uncertainty. Lastly, we cover three approaches to optimisation under uncertainty: stochastic programming, robust optimisation, and modelling to generate alternatives.


(content:uncert:uncertainty_in_optimisation)=
## Uncertainty in Energy System Optimisation Models
There are many sources of uncertainty in modelling. Uncertainty can be due to measurement errors (e.g. measurements of experiments or weather), prediction or estimation errors (e.g. predictions of future energy demand or prices), implementation errors, or inexact data (e.g. poor quality data).

Uncertainty can be classified into two types: structural uncertainty and parametric uncertainty. Structural uncertainty pertains to uncertainty in the model. In this case, we are unsure if the model is an accurate representation of reality. For example, it could be oversimplified, or it could fail to capture a certain factor realistically. Parametric uncertainty stems from limited information over the parameters of the model. In this case, we have confidence in the model, but we do not know the exact value of certain parameters, such as energy demand or wind speed. We will focus on parametric uncertainty.

When it comes to integrating renewable energy sources into energy systems, uncertainty arises due to the uncontrollability of many renewable sources. For example, the energy generated by a wind farm depends on the wind condition, which is a highly variable and uncertain parameter. On the other hand, conventional power plants can be entirely controlled by human operators, resulting in no uncertainty in energy production. Planning, operational, and market decisions all need to account for uncertainty.

### Optimisation problem with parametric uncertainty
The optimisation problem we aim to solve is as follows:
```{math}
:label: eqn:optimisation
\begin{align}
    \begin{split}
        \min_{\mathbf{x}}&~f(\mathbf{x}, \mathbf{z}) \\
        \text{s.t.}&~\mathbf{x} \in \mathcal{X}(\mathbf{z}) \\
    \end{split}
\end{align}
```

where $\mathbf{z}$ are the uncertain input parameters. $f(\mathbf{x},\mathbf{z})$ is the objective function with decision variables $\mathbf{x}$ which belong to the feasible region $\mathcal{X}(\mathbf{z})$ (constraints). In contrast to previously-studied optimisation problems, now the objective function is a function of the uncertain parameters $\mathbf{z}$ and the decision variables must belong to a feasible region that also depends on $\mathbf{z}$.

### Example: generation expansion planning

```{figure} ../images/gep_toyproblem_wCon_wObj.jpg
:name: fig:gen_exp
:figwidth: 600 px

Generation expansion planning problem with three generators A, B, and C that collectively meet demand given generation limits. The goal is to decide how much investment to make in the capacity of each generator while minimising cost.
```
Let's consider the example of generation expansion planning. Energy is produced by three generators: A, B, and C. The objective is to minimise total costs, which include fixed and variable costs of each generator. The decision variables $x_g$ represent the installed capacity of each generator (i.e. the investment made in each generation type). The decision variables $y_g$ represent the actual energy generation of each generator and must be greater than or equal to zero. There are a number of uncertain parameters in this problem: demand $d$, capacity factors $\tau_g$, fixed costs $f_g$, and variable costs $c_g$. The cost associated with running a generator is the fixed cost multiplied by the capacity investment plus the variable cost multiplied by the actual energy generation. This leads to the optimisation problem:
```{math}
\begin{align}
    \min&~\sum_{g} f_g x_g + \sum_{g} c_g y_g \\
    \text{s.t.}&~\sum_{g} y_g \geq d \\
    &~y_g \leq \tau_g x_g, &\forall g \in  \{A, B, C\}  \\
    &~y_g \geq 0, &\forall g \in  \{A, B, C\} \\
    &~x_g \in \{0,1,2,3\}, &\forall g \in  \{A, B, C\}
\end{align}
```

In this case, $\mathbf{x} = (x_A, x_B, x_C, y_A, y_B, y_C)$ so there are six decision variables; and $\mathbf{z} = (d, \tau_A, \tau_B, \tau_C, f_A, f_B, f_C, c_A, c_B, c_C)$ are the ten uncertain parameters. The first constraint is the demand constraint. The second and third constraints are the generation limits. The last constraint represents the level of investment in each generator.

## Static vs. Adaptive Problem Settings
In a static problem setting, the decisions $\mathbf{x}$ are made before the uncertain parameters $\mathbf{z}$ are observed. The decisions cannot be changed after the uncertain parameters are revealed. This leads to a single-stage optimisation problem and this is the type of problem setting we will consider. In the generation expansion planning example, the decisions of how much capacity investment to make in each generator have to be made before the uncertain parameters of demand, capacity factors, fixed costs, and variable costs are known. Once the uncertain parameters are revealed, the investment decision cannot be adjusted.

In contrast, an adaptive setting involves multiple stages of decisions. First, decisions $\mathbf{x}_0$ are made, then uncertain parameters $\mathbf{z}_1$ are observed. Then, the decision maker adapts to $\mathbf{z}_1$ and makes decisions $\mathbf{x}_1$. $\mathbf{z}_2$ are observed, $\mathbf{x}_2$ are decided, and so forth. Optimisation problems with more than two stages are very difficult to manage {cite:p}`dantzig1961solution` and are outside the scope of this course.

```{figure} ../images/static_opt_timeline.jpg
:name: fig:static
:figwidth: 350 px

Static problem setting
```

```{figure} ../images/multistage_kstage_timeline.jpg
:name: fig:adaptive
:figwidth: 600 px

Adaptive problem setting
```

## Uncertainty Characterisation
Characterising uncertainty is an important, but tricky, process. The aim is to quantify the uncertainty surrounding the input parameters $\mathbf{z}$. We would like to know what range of values an uncertain parameter is in.

There is no general best practice for quantifying uncertainty. It depends on the specific situation and can be "more of an art than a science." Uncertainty can be quantified based on historic data, external models, expert opinion, and/or subjective assumptions. Nevertheless, uncertainty characterisation can have a great impact on results, so it is a process not to be overlooked.

Exogenous uncertainty is outside our control whereas endogenous uncertainty can be affected by our decisions. The latter is generally more difficult to deal with {cite:p}`nohadani2018optimization`. An example of exogenous uncertainty is the weather, where for example wind speed or cloud coverage are outside our control. An example of endogenous uncertainty is global temperature. Our behavior in how much carbon dioxide we emit has an impact on the global temperature.

Uncertainty can also change over time. Here, we will consider three types shown in {numref}`fig:unc_time`. Type I, the investment type, concerns a decision (investment) made at one time, so only the uncertainty in the parameter at that time matters. In Type II, the range of uncertainty remains constant over time. Lastly, the type we generally face is Type III, which deals with increasing uncertainty over time.

```{figure} ../images/Moret2017_characterization_Fig5.jpg
:name: fig:unc_time
:figwidth: 500px

Uncertainty over time {cite:p}`moret2017strategic`
```

### Forecasting the future
Forecasts of weather and energy demand can help grid operators, renewable power plant operators, and energy traders make decisions. When forecasting the future, we can take several approaches ({numref}`fig:forecasting`). A point forecast uses past and present data to make one prediction of the future. It makes a conditional expectation of what may happen at a future time $t+k$ given our knowledge up to time $t$. It also does not communicate uncertainty because it gives a single forecast. A probabilistic forecast makes a range of predictions with a probability of each future outcome. The result is a probability density function for time $t+k$. Scenarios outline several possible discrete forecasts of the future. Each scenario is one realisation of a stochastic process. One possible approach is to analyse past forecast errors in order to generate possible future scenarios.

```{figure} ../images/forecasting_methods.png
:name: fig:forecasting

Different approaches to forecasting the future
```

An everyday example is forecasting the weather. We take some initial state of the weather, which has some uncertainty around it, shown by the circle on the left side of {numref}`fig:weather_forecasting`. A model generates possible pathways of weather development over time. The outcome depends on the initial condition. Therefore, there is uncertainty in the final weather forecast. The further out we try to forecast the weather, the lower the predictability becomes.

```{figure} ../images/weather_forecast_uncertainty.png
:name: fig:weather_forecasting

Example of weather forecasting {cite:p}`bauer2015quiet`
```

## Analysis of Uncertainty
We will now turn to analysing the potential impact of uncertain input parameters. Analysing uncertainty means properly describing and understanding the impact of model parameter variations on the model prediction. Due to an uncertain parameter, the outcome of a model can be desirable in one scenario and completely undesirable in another scenario, depending on the value of the uncertain parameter. Analysing uncertainty is an essential part of assessing any model. In particular, we will focus on sensitivity analysis and robustness analysis.

### Sensitivity analysis
Sensitivity analysis analyses the sensitivity of a model under variation in input parameters {cite:p}`saltelli2004sensitivity`. We change the value of the uncertain input parameters $\mathbf{z}$ and want to know 1) How does the optimal solution change? and 2) What is the optimal objective value?

It is assumed that the solution is fully flexible and able to adapt to changes in the model inputs. The solution is able to adapt with perfect foresight, so the uncertain parameters $\mathbf{z}$ are observed, then the decision is made ({numref}`fig:sensitivity`).

```{figure} ../images/SA_timeline.jpg
:name: fig:sensitivity
:figwidth: 400 px

Sensitivity analysis timeline
```

Recall the optimisation problem in Equation {eq}`eqn:optimisation`. We input a set of scenarios, $S = \{ \mathbf{z}^1, ...,\mathbf{z}^N \}$, and evaluate the sensitivity of the model with respect to each scenario in $S$. For each scenario $i$, we determine the optimal solution $\mathbf{x}^*$ by re-solving the optimisation problem. Once we have the solution, we evaluate the objective function value $f(\mathbf{x}^*, \mathbf{z}^i)$. This algorithm can be described as follows:
```{prf:algorithm} Sensitivity Analysis
:label: sensitivity-analysis-algorithm

**Input** Set of scenarios $\mathcal{S} = \left\{\mathbf{z}^{1}, \ldots, \mathbf{z}^{N}\right\}$

**Output** Evaluation of sensitivity of model w.r.t. each scenario in $\mathcal{S}$

**for** scenario $i \in \{1, \dotsc, N\}$ **do**\
     1: Determine optimal solution $\mathbf{x}^*$ by solving $\min\limits_{\mathbf{x}}\{f(\mathbf{x}, \mathbf{z}^{i})~|~\mathbf{x} \in \mathcal{X}(\mathbf{z}^{i}) \}$ \
     2: Evaluate objective value by computing $f(\mathbf{x}^*, \mathbf{z}^{i})$
```

### Robustness analysis
In robustness analysis, we analyse the robustness of a _fixed_ solution under variation in the input parameters {cite:p}`Hertog_BenTal_Brekelmans_Roos_2021`. This situation is shown in {numref}`fig:robustness` where the decision $\mathbf{x}$ is made, then the uncertain parameters $\mathbf{z}$ are revealed (and the decision cannot be changed). We change the value of the uncertain input parameters and want to know 1) Is the solution feasible? and 2) What is the optimal objective value?

```{figure} ../images/static_opt_timeline.jpg
:name: fig:robustness
:figwidth: 400 px

Robustness analysis timeline
```

Again, we consider a set of scenarios, $S = \{ \mathbf{z}^1, ...,\mathbf{z}^N \}$. Now we evaluate the robustness of a fixed solution $\bar{\mathbf{x}}$ with respect to each input scenario. For each scenario $i$, we first evaluate the feasibility by determining if the solution $\bar{\mathbf{x}}$ is in the feasible region $\mathcal{X}(\mathbf{z}^i)$. Then we compute the objective function value $f(\bar{\mathbf{x}}, \mathbf{z}^i)$. The algorithm is written as follows:
```{prf:algorithm} Robustness Analysis
:label: robustness-analysis-algorithm

**Input** Set of scenarios $\mathcal{S} = \left\{\mathbf{z}^{1}, \ldots, \mathbf{z}^{N}\right\}$, Given a solution $\bar{\mathbf{x}}$

**Output** Evaluation of robustness of $\bar{\mathbf{x}}$ w.r.t. each scenario in $\mathcal{S}$

**for** scenario $i \in \{1, \dotsc, N\}$ **do**\
    1: Evaluate feasibility by determining whether $\bar{\mathbf{x}} \in \mathcal{X}(\mathbf{z}^{i})$ \
    2: Evaluate objective value by computing $f(\bar{\mathbf{x}}, \mathbf{z}^{i})$
```

Note that unlike in sensitivity analysis, in robustness analysis, the model does not need to be re-solved for each scenario (because we consider a fixed solution). Only simple function evaluations are involved, so there is less computational effort than there is for sensitivity analysis.

### Local vs. global analysis
In local analysis, we evaluate how small perturbations in an input parameter affect the output of interest {cite:p}`trucano2006calibration`. Only one parameter, or a certain limited number of parameters, is altered at a time. By contrast, in global analysis, all the input parameters are varied simultaneously and they are varied over the whole domain of possible parameter values {cite:p}`Zhou2008`. There is a big difference in computational effort between local and global analysis when dealing with a large number of uncertain parameters.


## Optimisation under Uncertainty
It is important to assess uncertainty in energy system optimisation models. The three main approaches we will discuss are stochastic programming, robust optimisation, and modelling to generate alternatives.

### Stochastic programming
Consider the optimisation problem
\begin{align}
    \begin{split}
        \min_{\mathbf{x}}&~f(\mathbf{x}, \mathbf{z}) \\
        \text{s.t.}&~g(\mathbf{x}, \mathbf{z}) \leq 0 \\
    \end{split}
\end{align}
again with decision variables $\mathbf{x}$ and uncertain parameters $\mathbf{z}$. We assume that $\mathbf{z}$ is a realisation of random variables $\tilde{\mathbf{z}}$ with known probability distribution $\mathbb{P}$. We call this a stochastic process, which is a probability distribution over a set of paths describing the expected evolution of a random or uncertain variable. The variables can be discrete (e.g. policy decisions) or continuous (e.g. natural gas prices).

```{figure} ../images/probability_distributions.png
:name: fig:probability_distributions
:figwidth: 400px

Discrete vs. continuous probability distributions $\mathbb{P}$ of $\tilde{\mathbf{z}}$
```

Given knowledge of the probability distribution $\mathbb{P}$ of $\tilde{\mathbf{z}}$, we can reformulate the optimisation problem as a stochastic problem:
```{math}
:label: eqn:stochastic
\begin{align}
    \begin{split}
        \min_{\mathbf{x}}&~\mathbb{E}_{\mathbb{P}} \left[ f(\mathbf{x}, \tilde{\mathbf{z}}) \right] \\
        \text{s.t.}&~\mathbb{P} \left( g(\mathbf{x}, \tilde{\mathbf{z}}) \leq 0 \right) \geq 1-\epsilon \\
    \end{split}
\end{align}
```
$\mathbb{E}_{\mathbb{P}} \left[ f(\mathbf{x}, \tilde{\mathbf{z}}) \right]$ is the expected value of $f(\mathbf{x}, \tilde{\mathbf{z}})$, which is what we want to optimise now. The probability of constraint violation must be less than $\epsilon$. In Equation {eq}`eqn:stochastic`, this is written as the probability that the original constraint given $\tilde{\mathbf{z}}$ is true/satisfied must be greater than or equal to $1-\epsilon$. In other words, we want the solution to be feasible $1-\epsilon$ of the time, so the constraint must hold for a certain $(1-\epsilon)\%$ of $\tilde{\mathbf{z}}$. The value of $\epsilon$ is set by the modeler, depending on how much risk is acceptable.

#### Discrete probability distribution
Now that we have written the stochastic problem, we will move on to how to solve it. If the probability distribution $\mathbb{P}$ is discrete then the problem can be made deterministic. In this case, $\mathbb{P}$ consists of $N$ discrete scenarios $\mathbf{z}^1, \dotsc, \mathbf{z}^N$ that occur with known probabilities $p^1, \dotsc, p^N$. Then we rewrite the problem in Equation {eq}`eqn:stochastic` as:
```{math}
:label: eqn:stochastic_discrete
\begin{align}
    \begin{split}
        \min_{\mathbf{x}, \mathbf{b}}&~\sum\limits_{i=1}^N p^i f(\mathbf{x}, \mathbf{z}^i) \\
        \text{s.t.}&~g(\mathbf{x}, \mathbf{z}^i) \leq b^i M,~~i=1,\dotsc,N \\
        &~\sum\limits_{i=1}^N p^i b^i \leq \epsilon \\
    \end{split}
\end{align}
```
We introduce the binary variables $b^i \in \{0,1\}, i=1,\dotsc,N$. If $b^i$ is 0 then the constraint is not violated and if $b^i$ is 1 then the constraint is violated. The bottom line in Equation {eq}`eqn:stochastic_discrete` allows a limited number of constraints to be violated. $M$ is a sufficiently large constant. This deterministic problem can only be solved if the number of scenarios $N$ is not too large.

#### Continuous probability distribution
If the probability distribution $\mathbb{P}$ is continuous then there are only tractable reformulations for specific situations. For example, when $\tilde{\mathbf{z}}$ are uniformly distributed (a simple, well-known distribution) and $f$ and $g$ are linear functions. Because the distribution is continuous, there are an infinite number of possible scenarios and they are impossible to enumerate. Often, we have to use sampling-based approximations {cite:p}`homem2014monte`. Instead of dealing with probability distribution $\mathbb{P}$ in a direct manner, we sample $N$ scenarios $\mathbf{z}^1, \dotsc, \mathbf{z}^N$ from $\mathbb{P}$ and approximate the stochastic programming problem in Equation {eq}`eqn:stochastic`.

#### Stochastic programming example: demand response
In this example, we want to adjust demand to better match the fluctuating supply of renewable energy sources. A consumer performs a certain task that requires the use of electricity. The utility function $f_t(u_t)$ measures the benefit of consuming energy $u_t$ for the task during time period $t = 1, ..., T$.

##### {{ labeled_circle_params }}
We know that the total consumption for the four time periods together must be between 6 and 8 kWh.

We also know the consumption cannot be higher than $U_{max}$ = 3 kWh for each time period $t$.

We also know the ramping limit (up or down) is $U_{ramp}$ = 1.5 kWh between any two time periods.

Now we introduce uncertainty with a stochastic process. Electricity price per time period is an uncertain parameter. We consider price uncertainty with scenarios, indexed by $\omega$. $\lambda$ is the set of possible realisations of the stochastic process, or prices. $\lambda_\omega$ is a vector representing one possible realisation of the stochastic process. (Note that in this example, stochastic process = uncertain model parameter = price uncertainty.) Each realisation $\lambda_\omega$ is associated with a probability $\pi_\omega$. In this example, we consider a discrete probability distribution consisting of two scenarios so the probabilities $\pi_1$ and $\pi_2$ add up to 1. The table below shows the scenarios we consider.

| Scenario | Probability | Price | Price | Price | Price |
| --- | --- | --- | --- | --- | --- |
| $\omega$ | $\pi_\omega$ | $\lambda_1$| $\lambda_{2\omega}$ | $\lambda_{3\omega}$ | $\lambda_{4\omega}$ |
| 1 | 0.5 | 120 | 105 | 154 | 84 |
| 2 | 0.5 | 120 | 45 | 66 | 36 |

So, we have two scenarios with 50\% probability each. Note that $\lambda_1 = 120$ in both scenarios.

##### {{ labeled_circle_vars }}
We want to decide how much energy to consume $u_{t\omega}$ during time period $t = 1, ..., T$. Because we have two scenarios, and one certain time period, there are seven optimisation variables: $u_1, u_{21}, u_{31}, u_{41}, u_{22}, u_{32}, u_{42}$ (the consumption at $t=1$ and the scenario-dependent consumption at $t=2,3,4$).

##### {{ labeled_circle_obj }}
Our objective is to maximise welfare (minimise costs minus benefits):

\begin{align}
    \min \left[ \lambda_1 u_1 - f_1(u_1) + \sum_{\omega=1}^\Omega \pi_\omega \times \sum_{t=2}^T (\lambda_{t\omega} u_{t\omega} - f_t(u_{t\omega}) ) \right]
\end{align}

This is the implementation of the objective function in Equation {eq}`eqn:stochastic_discrete`. The first part with $t=1$ represents the certain part because $\lambda_1 = 120$ always. The utility function $f_t(u_t)$ is a linear function of consumption $u_t$: $f_t(u_t) = 100 u_t$.

##### {{ labeled_circle_constr }}
We have three practical constraints to consider.

First, the consumption per time period cannot be higher than $U_{max}$ = 3 kWh:

\begin{equation}
    U_{min} \leq u_t \leq U_{max}
\end{equation}

Second, the total consumption for the four periods together must be between 6 and 8 kWh.

Third, there is a ramping limit of 1.5 kWh between time periods.

##### Full problem
In our example, we end up with the following optimisation problem:

* Variables: $u_1, u_{21}, u_{31}, u_{41}, u_{22}, u_{32}, u_{42}$
* Objective (to be minimised):
\begin{equation}
    \begin{split}
        J = &  (120-100)u_1 + 0.5\left[(105-100)u_{21} + (154-100)u_{31} + (84-100)u_{41}\right] \\
        & + 0.5\left[(45-100)u_{22} + (66-100)u_{32} + (36-100)u_{42}\right]
    \end{split}
\end{equation}
* Consumption per time period constraint:
\begin{equation}
    \begin{split}
        0 \leq u_1 \leq 3 & \\
        0 \leq u_{t\omega} \leq 3 & \hspace{20 pt} \omega=1,2, t=2,3,4 \\
    \end{split}
\end{equation}
* Total consumption constraint:
\begin{equation}
    \begin{split}
        u_1 + \sum_t u_{t\omega} \leq 8 & \hspace{20 pt} \omega=1,2, t=2,3,4 \\
        u_1 + \sum_t u_{t\omega} \geq 6 & \hspace{20 pt} \omega=1,2, t=2,3,4 \\
    \end{split}
\end{equation}
* Ramping limits constraint:
\begin{equation}
    \begin{split}
        u_1 - u_0 \leq 1.5 & \hspace{20 pt} \omega=1,2, u_0=0 \\
        u_{2\omega} - u_1 \leq 1.5 & \hspace{20 pt} \omega=1,2 \\
        u_{t\omega} - u_{(t-1)\omega} \leq 1.5 & \hspace{20 pt} \omega=1,2, t=3,4 \\
        u_0 - u_1 \leq 1.5 & \hspace{20 pt} \omega=1,2, u_0=0 \\
        u_1 - u_{2\omega} \leq 1.5 & \hspace{20 pt} \omega=1,2 \\
        u_{(t-1)\omega} - u_{t\omega} \leq 1.5 & \hspace{20 pt} \omega=1,2, t=3,4 \\
    \end{split}
\end{equation}

##### Optimal solution
The optimal solution of our example is:
| Scenario | $u_1$ | $u_{2\omega}$ | $u_{3\omega}$ | $u_{4\omega}$ | Total |
| --- | --- | --- | --- | --- | --- |
| 1 | 0.25 | 1.75 | 1.25 | 2.75 | 6 |
| 2 | 0.25 | 1.75 | 3 | 3 | 8 |

```{figure} ../images/stochastic_programming_ex_soln.png
:name: fig:stochastic_programming_ex_soln
:figwidth: 450px

Optimal solution of energy consumption during each time period
```

We can think of our example as a two-stage stochastic programming problem. In the first stage (here and now), decisions $u$, not depending on the realisation of the uncertain parameters, are made. The parameters (price) in the first time period are certain so we can decide how much energy to consume now. Then, the outcome $\lambda_\omega$ of the random parameter vector $\lambda$ is realised. In the second stage (wait and see), the decisions $u_\omega$ are made according to $\lambda_\omega$. As the price in each time period is revealed, we adapt and decide how much energy to consume. This two-stage approach allows the decision-maker to adapt to the actual outcome of random events while still achieving the overall optimal outcome given the uncertainty.

#### Limitations of stochastic programming
Aside from the challenges associated with a continuous distribution, there are a number of other limitations of stochastic programming. In reality, the probability distribution $\mathbb{P}$ is often unknown. We do not actually know the probability with which the uncertain parameters $\mathbf{z}$ take on certain values. Even if $\mathbb{P}$ is known, solving stochastic programming exactly is only possible in certain cases. We mentioned a discrete distribution with a small number of scenarios or a continuous uniform distribution with linear functions. Otherwise, we have to rely on sampling-based approximations to solve stochastic programming problems. Lastly, as the number of uncertain parameters increases, the computational tractability of the problem quickly deteriorates. We want to realistically represent the uncertainty in a problem, but it still has to be solvable with a computer.

### Robust optimisation
Consider the optimisation problem
\begin{align}
    \begin{split}
        \min_{\mathbf{x}}&~f_0(\mathbf{x}, \mathbf{z}) \\
        \text{s.t.}&~f_1(\mathbf{x}, \mathbf{z}) \leq 0 \\
        &~~~~~\vdots \\
        &~f_m(\mathbf{x}, \mathbf{z}) \leq 0 \\
    \end{split}
\end{align}
again with decision variables $\mathbf{x}$ and uncertain parameters $\mathbf{z}$. There are $m$ constraints.

Now we reformulate the problem by moving the uncertainty to the constraints ("epigraph form"). $\theta$ is a deterministic objective function.
\begin{align}
    \begin{split}
        \min_{\mathbf{x},\theta}&~\theta \\
        \text{s.t.}&~f_0(\mathbf{x}, \mathbf{z}) \leq \theta \\
        &~f_1(\mathbf{x}, \mathbf{z}) \leq 0 \\
        &~~~~~\vdots \\
        &~f_m(\mathbf{x}, \mathbf{z}) \leq 0 \\
    \end{split}
\end{align}
Then we merge the multiple constraints into a single constraint:
\begin{align}
    \begin{split}
        \min_{\mathbf{x},\theta}&~\theta \\
        \text{s.t.}&~\underbrace{\max\{f_0(\mathbf{x}, \mathbf{z})-\theta, \max_{i=1,\dotsc,m} f_i(\mathbf{x}, \mathbf{z})\}}_{g(\mathbf{x}, \mathbf{z})} \leq 0 \\
    \end{split}
\end{align}
In "standard form", we write this as:
\begin{align}
    \begin{split}
        \min_{\mathbf{x}}&~f(\mathbf{x}) \\
        \text{s.t.}&~g(\mathbf{x}, \mathbf{z}) \leq 0 \\
    \end{split}
\end{align}
Note that there is no uncertainty in the objective function $f(\mathbf{x})$ (it is not a function of $\mathbf{z}$) and there is a single constraint $g(\mathbf{x}, \mathbf{z}) \leq 0$. Any problem can be rewritten in this "standard form", which is a deterministic optimisation problem.

Now we assume the uncertain parameters $\mathbf{z}$ are contained within some geometric "uncertainty set" $\mathcal{U}$. An example of an uncertainty set is shown in {numref}`fig:uncertainty_set`. The modeler can choose how large or small to make $\mathcal{U}$.

```{figure} ../images/uncertainty_set.png
:name: fig:uncertainty_set
:figwidth: 450px

Example geometric uncertainty set $\mathcal{U}$
```

Then we write the problem as:
\begin{align}
    \begin{split}
        \min_{\mathbf{x}}&~f(\mathbf{x}) \\
        \text{s.t.}&~g(\mathbf{x}, \mathbf{z}) \leq 0, ~~\forall \mathbf{z} \in \mathcal{U} \\
    \end{split}
\end{align}
The constraints must hold for all possible realisations of $\mathbf{z} \in \mathcal{U}$. We also optimise with respect to the worst-case of $\mathbf{z} \in \mathcal{U}$ because if the constraint holds for the worst-case $\mathbf{z}$ then it will hold for all other $\mathbf{z} \in \mathcal{U}$. Note that $\forall \mathbf{z} \in \mathcal{U}$ may imply an infinite number of constraints.

To solve the robust optimisation problem, we consider the reformulation approach and the adversarial approach.

#### Reformulation approach
The idea behind the reformulation approach is to solve the robust optimisation problem by reformulating it into a deterministic and finite equivalent, called a "robust counterpart". Depending on the shape of the uncertainty set, we can write a corresponding robust counterpart.

There are two important notes to make in the reformulation. The first is that $g(\mathbf{x}, \mathbf{z}) \leq 0, ~\forall \mathbf{z} \in \mathcal{U}$ is true if and only if $\max\limits_{\mathbf{z} \in \mathcal{U}}  g(\mathbf{x}, \mathbf{z}) \leq 0$. That is, if the constraint holds for the $\mathbf{z}$ that maximises $g$, then it holds for all other $\mathbf{z} \in \mathcal{U}$. Thus, we no longer have the issue of potentially an infinite number of constraints. Secondly, we can use duality to rewrite $\max\limits_{\mathbf{z} \in \mathcal{U}} \dots$ as $\min\limits_{\mathbf{y} \in \mathcal{Y}} \dots$. $\mathbf{y}$ are the dual variables. Now instead of a $\min\limits_{\mathbf{x}} \max\limits_{\mathbf{z}}$ problem, we have a $\min\limits_{\mathbf{x}} \min\limits_{\mathbf{y}}$ problem, which we can combine into a single $\min\limits_{\mathbf{x}, \mathbf{y}}$ problem.

#### Adversarial approach
The idea behind the adversarial approach is to solve the robust optimisation problem by viewing it as a game between the decision maker $\mathbf{x}$ and an "adversary" $\mathbf{z}$. The game is played as follows:
1. The decision maker makes the first move by optimising the problem for the nominal scenario $\mathbf{z}_{0}$ to obtain an initial solution $\mathbf{x}_0$ \
    $\begin{align}
        \min\limits_{\mathbf{x}}&~f(\mathbf{x}) \\
        \text{s.t.}&~g(\mathbf{x}, \mathbf{z}_{0}) \leq 0 ~\\
    \end{align}
    \bigg \rbrace \Rightarrow \mathbf{x}_0 $
2. The adversary searches for the worst possible counter to $\mathbf{x}_0$ by maximising $g$ given $\mathbf{x}_0$ to obtain a counter $\mathbf{z}_1$ \
    $\begin{align}
        \max\limits_{\mathbf{z}}&~g(\mathbf{x}_0, \mathbf{z})~ \\
        \text{s.t.}&~\mathbf{z} \in \mathcal{U}~~\\
    \end{align}
    \bigg \rbrace \Rightarrow \mathbf{z}_1  $ \
    Since the decision maker is trying to get $g \leq 0$, the adversary maximises $g$ to find the worst-case scenario. \
    $\ast$ If the adversary finds a counter $\mathbf{z}_1$ such that $g(\mathbf{x}_0, \mathbf{z}_1) > 0$, we continue by finding a new optimal solution (Step 3). If $g(\mathbf{x}_0, \mathbf{z}_1) > 0$ that means the constraint is violated so we have to continue looking for a solution. Otherwise, if $g(\mathbf{x}_0, \mathbf{z}_1) \leq 0$, then $\mathbf{x}_0$ is a solution to the robust optimisation problem so the game stops.
3.  The decision maker reacts to the adversary's counter $\mathbf{z}_1$ by looking for a new solution $\mathbf{x}_1$ \
    $\begin{align}
        \min\limits_{\mathbf{x}}&~f(\mathbf{x}) \\
        \text{s.t.}&~g(\mathbf{x}, \mathbf{z}_{0}) \leq 0, ~\\
        &~g(\mathbf{x}, \mathbf{z}_{1}) \leq 0, ~\\
    \end{align}
    \Biggr \rbrace \Rightarrow \mathbf{x}_1  $ \
    Now, there are two constraints, considering both $\mathbf{z}_0$ and $\mathbf{z}_1$.
4.  The adversary searches for the worst possible counter $\mathbf{z}_2$ to $\mathbf{x}_1$ \
    $\begin{align}
        \max\limits_{\mathbf{z}}&~g(\mathbf{x}_1, \mathbf{z})~ \\
        \text{s.t.}&~\mathbf{z} \in \mathcal{U}~~\\
    \end{align}
    \bigg \rbrace \Rightarrow \mathbf{z}_2  $ \
    $\ast$ If the adversary finds a counter $\mathbf{z}_2$ such that $g(\mathbf{x}_1, \mathbf{z}_2) > 0$, we continue by finding a new optimal solution. Otherwise, if $g(\mathbf{x}_1, \mathbf{z}_2) \leq 0$, then $\mathbf{x}_1$ is a solution to the robust optimisation problem so the game stops.
5.  The game continues with the decision maker reacting to the adversary's counter to obtain a new solution, then the adversary finding a worst possible counter, and so on. We continue until the adversary cannot find a counter that violates the constraint.

The following table summarizes the pros and cons of the reformulation approach and adversarial approach. The best approach depends on the situation {cite:p}`bertsimas2016reformulation`.
| **Reformulation approach** {cite:p}`ben1998robust` | **Adversarial approach** {cite:p}`mutapcic2009cutting` |
| --- | --- |
| + Single problem to solve | -- Iteratively solve multiple problems |
| -- Requires deriving robust counterpart | + Simple to implement |
| -- Problem size increased at start | + Problem size increases incrementally |
| -- More difficult when uncertainty set is non-convex | -- May require many iterations before convergence |

#### Limitations of robust optimisation
Robust optimisation relies on the assumption that the uncertain parameters $\mathbf{z}$ are contained within some uncertainty set $\mathcal{U}$. However, it is not always clear how to choose an appropriate shape and size of $\mathcal{U}$. This affects our ability to solve a robust optimisation problem. Additionally, our ability to solve a robust optimisation problem depends on the function $g$ and the uncertainty set $\mathcal{U}$. If $g$ is non-concave in $\mathbf{z}$, then exact reformulations of the problem are known for only certain combinations of $g$ and $\mathcal{U}$. Lastly, when solving robust optimisation problems in practice, it may involve an unacceptably large increase in the number of variables and constraints, making the problem difficult to solve even though it is theoretically tractable.

:::{admonition} Difference in key assumption between stochastic programming and robust optimisation
:class: important

The key assumption in stochastic programming is that the uncertain parameters are characterised by a known probability distribution.
The key assumption in robust opimisation is that the uncertain parameters are contained in some uncertainty set.

:::

#### Distributionally robust optimisation
The idea behind distributionally robust optimisation is to combine stochastic programming and robust optimisation. Recall the stochastic programming problem in Equation {eq}`eqn:stochastic` (repeated below):
\begin{align}
    \begin{split}
        \min_{\mathbf{x}}&~\mathbb{E}_{\mathbb{P}} \left[ f(\mathbf{x}, \tilde{\mathbf{z}}) \right] \\
        \text{s.t.}&~\mathbb{P} \left( g(\mathbf{x}, \tilde{\mathbf{z}}) \leq 0 \right) \geq 1-\epsilon \\
    \end{split}
\end{align}
$\mathbb{P}$ is the probability distribution of $\tilde{\mathbf{z}}$, which is often unknown. Thus, we assume $\mathbb{P}$ is contained within some "ambiguity set" $\mathcal{P}$. Think of $\mathcal{P}$ as a sort of equivalent to the uncertainty set $\mathcal{U}$ except for probability distributions.

```{figure} ../images/DRO_ambiguity_set.png
:name: fig:ambiguity_set
:figwidth: 300px

An ambiguity set $\mathcal{P}$ of probability distributions. The probability distribution $\mathbb{P}$ of $\tilde{\mathbf{z}}$ takes on one of these distributions, but we are uncertain as to which.
```

So we formulate a distributionally robust optimisation problem:
\begin{align}
    \begin{split}
        \min_{\mathbf{x}} \max_{\mathbb{P} \in \mathcal{P}}&~\mathbb{E}_{\mathbb{P}} \left[ f(\mathbf{x}, \tilde{\mathbf{z}}) \right] \\
        \text{s.t.}&~\mathbb{P} \left( g(\mathbf{x}, \tilde{\mathbf{z}}) \leq 0 \right) \geq 1-\epsilon,~~\forall \mathbb{P} \in \mathcal{P} \\
    \end{split}
\end{align}
We optimise with respect to the worst-case distribution $\mathbb{P} \in \mathcal{P}$. It turns out that distributionally robust optimisation can in many cases be solved more efficiently than stochastic programming.

### Modelling to generate alternatives
Real world problems are quite complex. They may not be captured realistically in a mathematical model. So instead of fixating on a single optimal solution, we can explore multiple near-optimal solutions. For example, we can make multiple scenarios for a carbon-neutral energy system {cite:p}`pickering2022diversity`. It is also helpful to provide policymakers with diverse solution options like a set of energy transition pathways.

{numref}`fig:MGA` shows the concept of exploring the near-optimal solution space. The gray area depicts the feasible space of solutions. The red x represents the single optimal solution $\mathbf{x}^*$ with corresponding optimal objective value $f(\mathbf{x}^*)$. The green area represents the solution space if we allow an $\epsilon \%$ increase in the objective value. We see that there are many similar solutions between $\underline{\mathbf{x}}^\epsilon$ and $\bar{\mathbf{x}}^\epsilon$ which are near-optimal.

```{figure} ../images/near_optimal_space.png
:name: fig:MGA

Exploring the near-optimal solution space in modelling to generate alternatives {cite:p}`neumann2021near`
```

There are a number of limitations of modelling to generate alternatives. Firstly, it does not deal with parametric uncertainty, but it does address structural uncertainty. Therefore, it is a good idea to pair it with robustness analysis. Secondly, for large-scale problems, there is a large number of possible search directions. Therefore, we may only be able to explore a limited part of the near-optimal solution space. Thirdly, it can be difficult to determine which alternatives are most desirable and to measure how diverse the set of alternatives is. The ultimate objective of the problem can be unclear or subjective.

## Summary
The table below compares the ways to deal with parametric uncertainty which were discussed in this chapter:
|  | Stochastic programming | Robust optimisation | Sensitivity analysis | Robustness analysis |
| --- | --- | --- | --- | --- |
| When do we do it | When formulating the model | When formulating the model | After we solve the model | After we solve the model |
| What do we need | Explicit quantification of scenarios with their probability for uncertain variables | Specification of an uncertainty set for uncertain variables | A model and a set of scenarios | A model, a set of scenarios, and a fixed solution |
| What do we get | Solution that includes the possibility for recourse---choosing one of several alternatives once we know more about the realisation of uncertain parameters | Solution that is feasible for any possible realisation of the uncertain parameters, and optimal for the worst case | Effect of changes in limited numbers of parameters on the optimal solution (e.g. by looking at shadow prices), but only for small perturbations around the optimal solution | Effect of changes in limited numbers of parameters on the feasibility of a fixed solution, but only for small perturbations in parameters |

In this chapter, we dealt primarily with parametric uncertainty. Be aware that there is more to dealing with uncertainty.
```{figure} ../images/uncertainty_summary.png
:name: fig:uncertainty_summary
:figwidth: 550px

Parametric uncertainty in the context of broader uncertainty (Adapted from {cite:p}`spiegelhalter`)
```

## References

```{bibliography}
:filter: docname in docnames
```